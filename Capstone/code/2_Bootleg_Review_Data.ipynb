{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "#import libraries\n",
    "import pandas as pd\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from spacy.language import Language\n",
    "\n",
    "import gensim\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../datasets/tripadvisor_mbs_210328_2334')\n",
    "df2 = pd.read_csv('../datasets/tripadvisor_mbs_210329_0953')\n",
    "df3 = pd.read_csv('../datasets/tripadvisor_mbs_210329_1218')\n",
    "df4 = pd.read_csv('../datasets/tripadvisor_mbs_210329_1342')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.rename(columns={'Unnamed: 0': 'rev_id'})\n",
    "df2 = df2.rename(columns={'Unnamed: 0': 'rev_id'})\n",
    "df3 = df3.rename(columns={'Unnamed: 0': 'rev_id'})\n",
    "df4 = df4.rename(columns={'Unnamed: 0': 'rev_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3, df4], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>property</th>\n",
       "      <th>rev_source</th>\n",
       "      <th>rev_date</th>\n",
       "      <th>rev_location</th>\n",
       "      <th>rev_title</th>\n",
       "      <th>rev_content</th>\n",
       "      <th>rev_score</th>\n",
       "      <th>rev_visit_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>691636950</td>\n",
       "      <td>mbs</td>\n",
       "      <td>tripadvisor</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Disappointing</td>\n",
       "      <td>We splurged on our last night in Singapore to ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>691610644</td>\n",
       "      <td>mbs</td>\n",
       "      <td>tripadvisor</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High class shopping and dining - The Shopee</td>\n",
       "      <td>Located opposite of one iconic building in Sin...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2019-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691452668</td>\n",
       "      <td>mbs</td>\n",
       "      <td>tripadvisor</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Amazing!!!</td>\n",
       "      <td>We stayed for just one night in July 2019 and ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2019-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>691335096</td>\n",
       "      <td>mbs</td>\n",
       "      <td>tripadvisor</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Iconic but too massive for me</td>\n",
       "      <td>Clearly the building is a Singapore landmark. ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>691325714</td>\n",
       "      <td>mbs</td>\n",
       "      <td>tripadvisor</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>A mazing</td>\n",
       "      <td>Stayed for 3 nights. Everything about the hote...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2019-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>391583435</td>\n",
       "      <td>mbs</td>\n",
       "      <td>tripadvisor</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>Romania</td>\n",
       "      <td>Nice visit</td>\n",
       "      <td>A short visit to Marina Bay on out way to Bali...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2016-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>391560184</td>\n",
       "      <td>mbs</td>\n",
       "      <td>tripadvisor</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>Australia</td>\n",
       "      <td>A Massive Surprise</td>\n",
       "      <td>We recently spent 5 nights (family of 5) at th...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2016-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>391552729</td>\n",
       "      <td>mbs</td>\n",
       "      <td>tripadvisor</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Great infinity pool, large scale hotel</td>\n",
       "      <td>Stayed for two night when we passed through Si...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2016-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>391522920</td>\n",
       "      <td>mbs</td>\n",
       "      <td>tripadvisor</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>Must go</td>\n",
       "      <td>This hotel is just AMAZING, you have to stay h...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2016-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>391416747</td>\n",
       "      <td>mbs</td>\n",
       "      <td>tripadvisor</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pricey but Well Worth the Experience</td>\n",
       "      <td>Stayed one night in a deluxe club room and we ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2016-07-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rev_id property   rev_source    rev_date    rev_location  \\\n",
       "0     691636950      mbs  tripadvisor  2019-07-01       Australia   \n",
       "1     691610644      mbs  tripadvisor  2019-07-01             NaN   \n",
       "2     691452668      mbs  tripadvisor  2019-07-01  United Kingdom   \n",
       "3     691335096      mbs  tripadvisor  2019-07-01         Belgium   \n",
       "4     691325714      mbs  tripadvisor  2019-07-01  United Kingdom   \n",
       "...         ...      ...          ...         ...             ...   \n",
       "4995  391583435      mbs  tripadvisor  2016-07-01         Romania   \n",
       "4996  391560184      mbs  tripadvisor  2016-07-01       Australia   \n",
       "4997  391552729      mbs  tripadvisor  2016-07-01       Australia   \n",
       "4998  391522920      mbs  tripadvisor  2016-07-01       Venezuela   \n",
       "4999  391416747      mbs  tripadvisor  2016-07-01             NaN   \n",
       "\n",
       "                                        rev_title  \\\n",
       "0                                   Disappointing   \n",
       "1     High class shopping and dining - The Shopee   \n",
       "2                                      Amazing!!!   \n",
       "3                   Iconic but too massive for me   \n",
       "4                                       A mazing    \n",
       "...                                           ...   \n",
       "4995                                   Nice visit   \n",
       "4996                           A Massive Surprise   \n",
       "4997       Great infinity pool, large scale hotel   \n",
       "4998                                     Must go    \n",
       "4999         Pricey but Well Worth the Experience   \n",
       "\n",
       "                                            rev_content  rev_score  \\\n",
       "0     We splurged on our last night in Singapore to ...        6.0   \n",
       "1     Located opposite of one iconic building in Sin...        8.0   \n",
       "2     We stayed for just one night in July 2019 and ...       10.0   \n",
       "3     Clearly the building is a Singapore landmark. ...        6.0   \n",
       "4     Stayed for 3 nights. Everything about the hote...       10.0   \n",
       "...                                                 ...        ...   \n",
       "4995  A short visit to Marina Bay on out way to Bali...        8.0   \n",
       "4996  We recently spent 5 nights (family of 5) at th...       10.0   \n",
       "4997  Stayed for two night when we passed through Si...        6.0   \n",
       "4998  This hotel is just AMAZING, you have to stay h...       10.0   \n",
       "4999  Stayed one night in a deluxe club room and we ...       10.0   \n",
       "\n",
       "     rev_visit_date  \n",
       "0        2019-07-01  \n",
       "1        2019-07-01  \n",
       "2        2019-07-01  \n",
       "3        2019-07-01  \n",
       "4        2019-07-01  \n",
       "...             ...  \n",
       "4995     2016-07-01  \n",
       "4996     2016-07-01  \n",
       "4997     2016-07-01  \n",
       "4998     2016-07-01  \n",
       "4999     2016-07-01  \n",
       "\n",
       "[5000 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now break our review content into sentences. The sentences will also be broken at the word 'but' due to content before and after 'but' being of contrasting opinion. We will do this by adding a modification to SpaCy's sentencizer method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.set_custom_boundaries(doc)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@Language.component(\"set_custom_boundaries\")\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == \"but\":\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(\"set_custom_boundaries\", before=\"parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    '''\n",
    "    Function removes contractions from strings and replaces them with their un-contracted form to assist in tokenization.\n",
    "    Returns a string.\n",
    "    '''\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)      # replace won't with \"will not\"\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)      # replace can or cant with 'can not'\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)           # replece n with 'not'\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)           # replace re with 'are'\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)             # replace s with 'is'\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)          # replace 'd' with 'would'\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)          # replace 'll with 'will'\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)            # replace 't' with 'not'\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)          # replace ve with 'have'\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)             # replace 'm with 'am'\n",
    "    return phrase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_df_pp(raw_table):\n",
    "    '''\n",
    "    Function updates df_pp with preprocessed data from raw tables\n",
    "    returns modified df\n",
    "    '''\n",
    "    pp_columns = ['rev_id', # review id from raw_table\n",
    "                  'sent_text', # sentence_text from spaCy .sents\n",
    "#                   'sent_sw', # sentence with stopwords removed by spaCy\n",
    "                  'objects', # list of found dobj and pobj and nsubj\n",
    "#                   'contains_staff_terms', # contains words from list of words commonly associated with staff, indicating its talking about service\n",
    "#                   'contains_names', # contains names, indicating that its probably talking about service\n",
    "                  'contains_not_have', # contains the words no or not have, indicating possible indication of absence\n",
    "                  'descriptive', # adjectives and adverbs -- indicating sentiment\n",
    "                  'vader_neg', # vader sentiment negative score\n",
    "                  'vader_neu', # vader sentiment neutral scores\n",
    "                  'vader_pos', # vader sentiment positive score\n",
    "                  'vader_comp', # vader compound score\n",
    "                  'category', # category -- will be manually entered for training set\n",
    "                  'sentiment', # overall sentence sentiment\n",
    "                 ]\n",
    "    df_pp = pd.DataFrame(columns = pp_columns)\n",
    "    pp_index = 0\n",
    "    \n",
    "#     Index(['rev_id', 'property', 'rev_source', 'rev_date', 'rev_location',\n",
    "#        'rev_title', 'rev_content', 'rev_score', 'rev_visit_date'],\n",
    "#       dtype='object')\n",
    "    \n",
    "    for index, row in raw_table.iterrows(): # iterate through rows in raw_table\n",
    "        # insert rev_id\n",
    "        review_id = row['rev_id']\n",
    "   \n",
    "        doc = nlp(row['rev_content'])\n",
    "        #iterate through sentences\n",
    "        for sentence in doc.sents:\n",
    "            # insert review id\n",
    "            df_pp.loc[pp_index, 'rev_id'] = review_id\n",
    "            \n",
    "            # insert sentence\n",
    "            df_pp.loc[pp_index, 'sent_text'] = sentence.text\n",
    "                        \n",
    "            sentence_mod = decontracted(sentence.text)\n",
    "            # insert sentence with stop words removed\n",
    "            \n",
    "            # does sentence contain a not have negation?\n",
    "            df_pp.loc[pp_index, 'contains_not_have'] = contains_not_have(sentence_mod)\n",
    "            \n",
    "            descriptive_terms = []\n",
    "            target = []\n",
    "            contains_names = False\n",
    "            contains_staff_terms = False\n",
    "\n",
    "            \n",
    "            for token in sentence:\n",
    "                 # get objects for reference\n",
    "                if token.dep_ == 'dobj' or token.dep_ == 'pobj' or token.dep_ == 'nsubj':\n",
    "                    target.append(token.text)\n",
    "             \n",
    "                # get descriptive terms for reference\n",
    "                if token.pos_ == 'ADJ':\n",
    "                    prepend = ''\n",
    "                    for child in token.children:\n",
    "                        if child.pos_ != 'ADV':\n",
    "                              continue\n",
    "                        prepend += child.text + ' '\n",
    "                    descriptive_terms.append(prepend + token.text)\n",
    "                        \n",
    "            df_pp.loc[pp_index, 'objects'] = \", \".join(target)\n",
    "            df_pp.loc[pp_index, 'descriptive'] = \", \".join(descriptive_terms)\n",
    "            \n",
    "            #vader sentiment analysis -- bootlegging of sentiment analysis\n",
    "            sid = SentimentIntensityAnalyzer()\n",
    "            ss = sid.polarity_scores(sentence.text)\n",
    "            df_pp.loc[pp_index, 'vader_neg'] = ss['neg']\n",
    "            df_pp.loc[pp_index, 'vader_neu'] = ss['neu']\n",
    "            df_pp.loc[pp_index, 'vader_pos'] = ss['pos']\n",
    "            df_pp.loc[pp_index, 'vader_comp'] = ss['compound']\n",
    "            \n",
    "            # overall sentiment started as vader_comp rounded up or down\n",
    "            if ss['compound'] > 0.1:\n",
    "                df_pp.loc[pp_index, 'sentiment'] = 1\n",
    "            elif ss['compound'] = 0:\n",
    "                df_pp.loc[pp_index, 'sentiment'] = 0\n",
    "            elif ss['compound'] < 0:\n",
    "                df_pp.loc[pp_index, 'sentiment'] = -1\n",
    "            \n",
    "            # enter new row for new sentence\n",
    "            pp_index += 1\n",
    "    # return full df_pp\n",
    "    return df_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = update_df_pp(df[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['batch_date'] = '210415'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['contains_not_have'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('../testdata/test_df_210415.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
